{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook prep from Chap 9 Train, Validate, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Sequence\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pandas.api.types import is_string_dtype, is_object_dtype, is_categorical_dtype\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_log_error, mean_squared_error, r2_score\n",
    "\n",
    "from rfpimp import *  # feature importance plot\n",
    "\n",
    "bookcolors = {\n",
    "    'crimson': '#a50026', 'red': '#d73027',\n",
    "    'redorange': '#f46d43', 'orange': '#fdae61',\n",
    "    'yellow': '#fee090', 'sky': '#e0f3f8',\n",
    "    'babyblue': '#abd9e9', 'lightblue': '#74add1',\n",
    "    'blue': '#4575b4', 'purple': '#313695'}\n",
    "\n",
    "def test(X, y, n_estimators=50,\n",
    "         max_features='auto', min_samples_leaf=1):\n",
    "    rf = RandomForestRegressor(n_estimators=n_estimators,\n",
    "                               n_jobs=-1,\n",
    "                               oob_score=True,\n",
    "                               max_features=max_features, \n",
    "                               min_samples_leaf=min_samples_leaf)\n",
    "    rf.fit(X, y)\n",
    "    oob = rf.oob_score_\n",
    "    n = rfnnodes(rf)\n",
    "    h = np.median(rfmaxdepths(rf))\n",
    "    print(f\"OOB R^2 {oob:.5f} using {n:,d} tree nodes with {h} median tree height\")\n",
    "    return rf, oob\n",
    "        \n",
    "def df_split_dates(df,colname):\n",
    "    df[\"saleyear\"] = df[colname].dt.year\n",
    "    df[\"salemonth\"] = df[colname].dt.month\n",
    "    df[\"saleday\"] = df[colname].dt.day\n",
    "    df[\"saledayofweek\"] = df[colname].dt.dayofweek\n",
    "    df[\"saledayofyear\"] = df[colname].dt.dayofyear\n",
    "    df[colname] = df[colname].astype(np.int64) # convert to seconds since 1970\n",
    "    # age can be nan since YearMade can be nan\n",
    "    df['age'] = df['saleyear'] - df['YearMade'] # synthesize age\n",
    "\n",
    "def extract_sizes(df, colname):\n",
    "    df[colname] = df[colname].str.extract(r'([0-9.]*)', expand=True)\n",
    "    df[colname] = df[colname].replace('', np.nan)\n",
    "    df[colname] = pd.to_numeric(df[colname])\n",
    "    \n",
    "def df_normalize_strings(df):\n",
    "    for col in df.columns:\n",
    "        if is_string_dtype(df[col]) or is_object_dtype(df[col]):\n",
    "            df[col] = df[col].str.lower()\n",
    "            df[col] = df[col].fillna(np.nan) # make None -> np.nan\n",
    "            df[col] = df[col].replace('none or unspecified', np.nan)\n",
    "            df[col] = df[col].replace('none', np.nan)\n",
    "            df[col] = df[col].replace('#name?', np.nan)\n",
    "            df[col] = df[col].replace('', np.nan)\n",
    "\n",
    "def df_cat_to_catcode(df:pd.DataFrame):\n",
    "    for colname in df.columns:\n",
    "        if is_categorical_dtype(df[colname]):\n",
    "            df[colname] = df[colname].cat.codes + 1\n",
    "            \n",
    "def fix_missing_num(df, colname):\n",
    "    df[colname+'_na'] = pd.isnull(df[colname])\n",
    "    df[colname].fillna(df[colname].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    del df['MachineID'] # dataset has inconsistencies\n",
    "    del df['SalesID']   # unique sales ID so not generalizer\n",
    "\n",
    "    df['auctioneerID'] = df['auctioneerID'].astype(str)\n",
    "\n",
    "    df_normalize_strings(df)\n",
    "\n",
    "    extract_sizes(df, 'Tire_Size')\n",
    "    extract_sizes(df, 'Undercarriage_Pad_Width')\n",
    "\n",
    "    df.loc[df['YearMade']<1950, 'YearMade'] = np.nan\n",
    "    df.loc[df.eval(\"saledate.dt.year < YearMade\"), 'YearMade'] =         df['saledate'].dt.year\n",
    "\n",
    "    df.loc[df.eval(\"MachineHoursCurrentMeter==0\"),\n",
    "           'MachineHoursCurrentMeter'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_order_product_size(df):\n",
    "    sizes = {np.nan:0, 'mini':1, 'compact':1, 'small':2, 'medium':3,\n",
    "             'large / medium':4, 'large':5}\n",
    "    df['ProductSize'] = df['ProductSize'].map(sizes).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(df, colname):\n",
    "    ascat = df[colname].astype('category').cat.as_ordered()\n",
    "    onehot = pd.get_dummies(df[colname], prefix=colname, dtype=bool)\n",
    "    del df[colname]\n",
    "    df = pd.concat([df, onehot], axis=1)\n",
    "    # return altered dataframe and column training categories\n",
    "    return df, ascat.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_fiProductClassDesc(df):\n",
    "    df_split = df.fiProductClassDesc.str.split(' - ',expand=True).values\n",
    "    df['fiProductClassDesc'] = df_split[:,0] \n",
    "    df['fiProductClassSpec'] = df_split[:,1] # temporary column\n",
    "    pattern = r'([0-9.\\+]*)(?: to ([0-9.\\+]*)|\\+) ([a-zA-Z ]*)'\n",
    "    spec = df['fiProductClassSpec']\n",
    "    df_split = spec.str.extract(pattern, expand=True).values\n",
    "    df['fiProductClassSpec_lower'] = pd.to_numeric(df_split[:,0])\n",
    "    df['fiProductClassSpec_upper'] = pd.to_numeric(df_split[:,1])\n",
    "    df['fiProductClassSpec_units'] = df_split[:,2]\n",
    "    del df['fiProductClassSpec'] # remove temporary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_eng(X): # for later use\n",
    "    df_split_dates(X, 'saledate')\n",
    "    df_order_product_size(X)\n",
    "    split_fiProductClassDesc(X)\n",
    "\n",
    "    X, hf_cats = onehot(X, 'Hydraulics_Flow')\n",
    "    # normalize categories first then one-hot encode\n",
    "    X['Enclosure'] = X['Enclosure'].replace('erops w ac', 'erops ac')\n",
    "    X['Enclosure'] = X['Enclosure'].replace('no rops', np.nan)\n",
    "    X, enc_cats = onehot(X, 'Enclosure')\n",
    "    catencoders = {'Hydraulics_Flow':hf_cats,\n",
    "                   'Enclosure':enc_cats}\n",
    "\n",
    "    return X, catencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_fix_missing_nums(df:pd.DataFrame) -> dict:\n",
    "    medians = {}  # column name to median\n",
    "    for colname in df.columns:\n",
    "        if is_numeric_dtype(df[colname]):\n",
    "            medians[colname] = df[colname].median(skipna=True)\n",
    "            fix_missing_num(df, colname)\n",
    "    return medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_string_to_cat(df:pd.DataFrame) -> dict:\n",
    "    catencoders = {}\n",
    "    for colname in df.columns:\n",
    "        if is_string_dtype(df[colname]) or is_object_dtype(df[colname]):\n",
    "            df[colname] = df[colname].astype('category').cat.as_ordered()\n",
    "            catencoders[colname] = df[colname].cat.categories\n",
    "    return catencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize(X, catencoders):\n",
    "    medians = df_fix_missing_nums(X)            \n",
    "    e = df_string_to_cat(X)\n",
    "    catencoders.update(e)\n",
    "    df_cat_to_catcode(X)    \n",
    "    return medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(\"data/bulldozer-train.feather\")\n",
    "df = df.iloc[-100_000:] # same 100,000 records as before\n",
    "X, y = df.drop('SalePrice', axis=1), df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log(y)\n",
    "clean(X)\n",
    "X, catencoders = feature_eng(X)\n",
    "medians = numericalize(X, catencoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf, r2_train = test(X, y, n_estimators=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_fix_missing_test_nums(df_test, medians):\n",
    "    for colname in medians:\n",
    "        df_test[colname+'_na'] = pd.isnull(df_test[colname])\n",
    "        df_test[colname].fillna(medians[colname], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_apply_cats(df_test:pd.DataFrame, catencoders:dict):\n",
    "    for colname,encoder in catencoders.items():\n",
    "        # encode with categories from training set\n",
    "        df_test[colname] =             pd.Categorical(df_test[colname],\n",
    "                           categories=encoder, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_apply_cats(df_test, colname, catencoders):\n",
    "    df_test[colname] =         pd.Categorical(df_test[colname],\n",
    "                       categories=catencoders[colname],\n",
    "                       ordered=True)\n",
    "    onehot = pd.get_dummies(df_test[colname], prefix=colname, dtype=bool)\n",
    "    del df_test[colname]\n",
    "    df_test = pd.concat([df_test, onehot], axis=1)\n",
    "    del catencoders[colname] # simplify df_apply_cats()\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_eng_test(df_test, catencoders):\n",
    "    df_split_dates(df_test, 'saledate')\n",
    "    df_order_product_size(df_test)\n",
    "    split_fiProductClassDesc(df_test)\n",
    "\n",
    "    df_test = onehot_apply_cats(df_test, 'Hydraulics_Flow', catencoders)\n",
    "    df_test['Enclosure'] = df_test['Enclosure'].replace('erops w ac', 'erops ac')\n",
    "    df_test['Enclosure'] = df_test['Enclosure'].replace('no rops', np.nan)\n",
    "    df_test = onehot_apply_cats(df_test, 'Enclosure', catencoders)\n",
    "\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize_test(df_test:pd.DataFrame, medians:dict, catencoders:dict):\n",
    "    df_apply_cats(df_test, catencoders)\n",
    "    df_fix_missing_test_nums(df_test, medians)\n",
    "    df_cat_to_catcode(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.read_feather(\"data/bulldozer-valid.feather\")\n",
    "X_valid, y_valid = df_valid.drop('SalePrice', axis=1), df_valid['SalePrice']\n",
    "\n",
    "y_valid = np.log(y_valid)\n",
    "clean(X_valid)\n",
    "X_valid = feature_eng_test(X_valid, catencoders)\n",
    "numericalize_test(X_valid, medians, catencoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = X_valid.reindex(columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "y_pred = rf.predict(X_valid)\n",
    "# Use np.exp(y_valid) to get back into dollars space\n",
    "mae_valid_baseline = mean_absolute_error(np.exp(y_valid), np.exp(y_pred))\n",
    "rmsle_valid_baseline = np.sqrt( mean_squared_error(y_valid, y_pred) )\n",
    "r2_valid_baseline = rf.score(X_valid, y_valid)\n",
    "print(f\"Validation R^2 {r2_valid_baseline:.5f}, \"+\n",
    "      f\"RMSLE {rmsle_valid_baseline:.5f}, \"+\n",
    "      f\"MAE ${mae_valid_baseline:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(\"data/bulldozer-train.feather\")\n",
    "df = df.query('saledate.dt.year>=2007').copy()\n",
    "X, y = df.drop('SalePrice', axis=1), df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log(y)\n",
    "clean(X)\n",
    "X, catencoders = feature_eng(X)\n",
    "medians = numericalize(X, catencoders)\n",
    "\n",
    "df_valid = pd.read_feather(\"data/bulldozer-valid.feather\")\n",
    "X_valid, y_valid = df_valid.drop('SalePrice', axis=1), df_valid['SalePrice']\n",
    "y_valid = np.log(y_valid)\n",
    "clean(X_valid)\n",
    "X_valid = feature_eng_test(X_valid, catencoders)\n",
    "df_apply_cats(X_valid, catencoders)\n",
    "df_fix_missing_test_nums(X_valid, medians)\n",
    "df_cat_to_catcode(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_valid(X, y, X_valid, y_valid, n_estimators=200,\n",
    "               max_features='auto', min_samples_leaf=1):\n",
    "    X_valid = X_valid.reindex(columns=X.columns)\n",
    "    rf = RandomForestRegressor(n_estimators=n_estimators,\n",
    "                               n_jobs=-1,\n",
    "                               oob_score=True,\n",
    "                               max_features=max_features, \n",
    "                               min_samples_leaf=min_samples_leaf)\n",
    "    rf.fit(X, y)\n",
    "    n = rfnnodes(rf)\n",
    "    h = np.median(rfmaxdepths(rf))\n",
    "    y_pred = rf.predict(X_valid)\n",
    "    mae_valid = mean_absolute_error(np.exp(y_valid), np.exp(y_pred))\n",
    "    rmsle_valid = np.sqrt( mean_squared_error(y_valid, y_pred) )\n",
    "    r2_score_valid = rf.score(X_valid, y_valid)\n",
    "    print(f\"OOB R^2 {rf.oob_score_:.5f} using {n:,d} tree nodes {h} median tree height\")\n",
    "    print(f\"Validation R^2 {r2_score_valid:.5f}, RMSLE {rmsle_valid:.5f}, MAE ${mae_valid:.0f}\")\n",
    "    return rf, r2_score_valid, rmsle_valid, mae_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf, r2_score_2007, rmsle_2007, mae_2007 =     test_valid(X, y, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrees = 200\n",
    "minleaf = 1\n",
    "for maxf in np.arange(.1,.6,.1):\n",
    "    print(f\"n_estimators={ntrees}, max_features={maxf:.1f}, min_samples_leaf={minleaf}\")\n",
    "    test_valid(X, y, X_valid, y_valid,\n",
    "               max_features=maxf, min_samples_leaf=minleaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxf = .3\n",
    "for minleaf in range(2,7):\n",
    "   print(f\"n_estimators={ntrees}, max_features={maxf}, min_samples_leaf={minleaf}\")\n",
    "   test_valid(X, y, X_valid, y_valid,\n",
    "              max_features=maxf, min_samples_leaf=minleaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf, r2_score_valid, rmsle_valid, mae_valid =     test_valid(X, y, X_valid, y_valid,\n",
    "               max_features=.3, min_samples_leaf=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = importances(rf, X_valid, y_valid)\n",
    "plot_importances(I.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X, y, X_valid, y_valid, drop=0.10):\n",
    "   min_rmsle = 99999\n",
    "   X_valid = X_valid.reindex(columns=X.columns)\n",
    "   rf, _, rmsle, _ = test_valid(X, y, X_valid, y_valid,\n",
    "                                max_features=.3, min_samples_leaf=2)\n",
    "   I = importances(rf, X_valid, y_valid)\n",
    "   features = list(I.index)\n",
    "   keep = best_features = features\n",
    "   n = int(.9/drop) # how many iterations? get to 90%\n",
    "   for i in range(1,n+1):\n",
    "       X2 = X[keep]\n",
    "       X_valid2 = X_valid[keep]\n",
    "       print(f\"\n",
    "Num features = {len(keep)}\")\n",
    "       rf2, _, rmsle, _ = test_valid(X2, y, X_valid2, y_valid,\n",
    "                                     max_features=.3, min_samples_leaf=2)\n",
    "       if rmsle < min_rmsle:\n",
    "           min_rmsle = rmsle\n",
    "           best_features = keep\n",
    "       I2 = importances(rf2, X_valid2, y_valid) # recompute since collinear\n",
    "       features = list(I2.index)\n",
    "       keep = features[0:int(len(features)*(1-drop))]\n",
    "\n",
    "   return min_rmsle, best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = ['age', 'ProductSize', 'fiProductClassSpec_lower', 'fiSecondaryDesc', 'YearMade', 'fiProductClassSpec_upper', 'Hydraulics_Flow_standard', 'fiModelDesc', 'fiBaseModel', 'ModelID', 'Enclosure_erops ac', 'fiProductClassSpec_units', 'fiModelDescriptor', 'age_na', 'ProductGroupDesc', 'YearMade_na', 'ProductGroup', 'Engine_Horsepower', 'Hydraulics', 'fiModelSeries', 'Enclosure_orops', 'MachineHoursCurrentMeter', 'fiProductClassDesc', 'Drive_System', 'state', 'auctioneerID', 'fiProductClassSpec_lower_na', 'Transmission', 'Track_Type', 'fiProductClassSpec_upper_na', 'Steering_Controls', 'Ripper', 'Ride_Control']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[best_features]\n",
    "X_valid = X_valid[best_features]\n",
    "rf, r2_score_bestf, rmsle_bestf, mae_bestf =     test_valid(X, y, X_valid, y_valid,\n",
    "               max_features=.3, min_samples_leaf=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = rf.predict(X_valid)\n",
    "underprediction = np.mean(y_valid-y_valid_pred)\n",
    "dollars = np.mean(np.exp(y_valid)-np.exp(y_valid_pred))\n",
    "print(f\"Model underpredicts by ${dollars:.0f}, {underprediction:.5f} log(dollars)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!y_valid_pred = rf.predict(X_valid) + underprediction\n",
    "mae_best = mean_absolute_error(np.exp(y_valid), np.exp(y_valid_pred))\n",
    "rmsle_best = np.sqrt( mean_squared_error(y_valid, y_valid_pred) )\n",
    "r2_score_best = r2_score(y_valid, y_valid_pred)\n",
    "print(f\"Adjusted-model validation R^2 {r2_score_best:.5f}, RMSLE {rmsle_best:.5f}, MAE {mae_best:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(\"data/bulldozer-train-all.feather\")\n",
    "df = df.query('saledate.dt.year>=2007').copy()\n",
    "X, y = df.drop('SalePrice', axis=1), df['SalePrice']\n",
    "y = np.log(y)\n",
    "clean(X)\n",
    "X, catencoders = feature_eng(X)\n",
    "medians = numericalize(X, catencoders)\n",
    "X = X[best_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_feather(\"data/bulldozer-test.feather\")\n",
    "X_test, y_test = df_test.drop('SalePrice', axis=1), df_test['SalePrice']\n",
    "y_test = np.log(y_test)\n",
    "clean(X_test)\n",
    "X_test = feature_eng_test(X_test, catencoders)\n",
    "df_apply_cats(X_test, catencoders)\n",
    "df_fix_missing_test_nums(X_test, medians)\n",
    "df_cat_to_catcode(X_test)\n",
    "X_test = X_test[best_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf, r2_score_test, rmsle_test, mae_test =     test_valid(X, y + underprediction,\n",
    "               X_test, y_test,\n",
    "               max_features=.3, min_samples_leaf=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [\n",
    " [\"Training 100k records\", r2_valid_baseline, rmsle_valid_baseline, f\"{mae_valid_baseline:.0f}\"],\n",
    " [\"Training set >= 2007\", r2_score_2007, rmsle_2007, f\"{mae_2007:.0f}\"],\n",
    " [\"After tuning\", r2_score_valid, rmsle_valid, f\"{mae_valid:.0f}\"],\n",
    " [\"Best feature subset\", r2_score_bestf, rmsle_bestf, f\"{mae_bestf:.0f}\"],\n",
    " [\"Inflation adjusted\", r2_score_best, rmsle_best, f\"{mae_best:.0f}\"],\n",
    " [\"Test set\", r2_score_test, rmsle_test, f\"{mae_test:.0f}\"]\n",
    "]\n",
    "stats = pd.DataFrame(scores, columns=[\"Stage\", \"OOB R^2\",\"RMSLE\",\"MAE\"])\n",
    "stats = stats.set_index(\"Stage\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
